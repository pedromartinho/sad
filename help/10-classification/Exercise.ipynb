{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression binary classification exercise\n",
    "\n",
    "In this exercise you will be working with the [affairs dataset](http://statsmodels.sourceforge.net/stable/datasets/generated/fair.html) based on a survei of women on 1974 where they asked them whether they had extramarital affairs.\n",
    "\n",
    "To Correctly work with the database we will be splitting the data into training (X_train and y_train matrices) and test data (X_test and y_test).\n",
    "\n",
    "We ask you to:\n",
    "\n",
    "1) Build a binary classifier trained on the training data, and compute its classification accuracy\n",
    "\n",
    "2) Test the classification accuracy on the test data given the model you just trained\n",
    "\n",
    "3) create a new sample modeling a virtual surveyed woman (you can randomly set parameters for it) and see whether your new sample would cheat or not on her husband.\n",
    "\n",
    "Consider doing some plotting and printing out of the data along the way to get a feeling of what you are looking at in here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4456.000000</td>\n",
       "      <td>4456.000000</td>\n",
       "      <td>4456.000000</td>\n",
       "      <td>4456.000000</td>\n",
       "      <td>4456.000000</td>\n",
       "      <td>4456.00000</td>\n",
       "      <td>4456.000000</td>\n",
       "      <td>4456.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.116248</td>\n",
       "      <td>29.098070</td>\n",
       "      <td>9.017504</td>\n",
       "      <td>1.398900</td>\n",
       "      <td>2.414946</td>\n",
       "      <td>14.23070</td>\n",
       "      <td>3.419659</td>\n",
       "      <td>3.865575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.959071</td>\n",
       "      <td>6.788485</td>\n",
       "      <td>7.226163</td>\n",
       "      <td>1.427461</td>\n",
       "      <td>0.877166</td>\n",
       "      <td>2.19748</td>\n",
       "      <td>0.935788</td>\n",
       "      <td>1.344939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rate_marriage          age  yrs_married     children    religious  \\\n",
       "count    4456.000000  4456.000000  4456.000000  4456.000000  4456.000000   \n",
       "mean        4.116248    29.098070     9.017504     1.398900     2.414946   \n",
       "std         0.959071     6.788485     7.226163     1.427461     0.877166   \n",
       "min         1.000000    17.500000     0.500000     0.000000     1.000000   \n",
       "25%         4.000000    22.000000     2.500000     0.000000     2.000000   \n",
       "50%         4.000000    27.000000     6.000000     1.000000     2.000000   \n",
       "75%         5.000000    32.000000    16.500000     2.000000     3.000000   \n",
       "max         5.000000    42.000000    23.000000     5.500000     4.000000   \n",
       "\n",
       "             educ   occupation  occupation_husb  \n",
       "count  4456.00000  4456.000000      4456.000000  \n",
       "mean     14.23070     3.419659         3.865575  \n",
       "std       2.19748     0.935788         1.344939  \n",
       "min       9.00000     1.000000         1.000000  \n",
       "25%      12.00000     3.000000         3.000000  \n",
       "50%      14.00000     3.000000         4.000000  \n",
       "75%      16.00000     4.000000         5.000000  \n",
       "max      20.00000     6.000000         6.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd #used for reading/writing data \n",
    "import numpy as np #numeric library library\n",
    "from matplotlib import pyplot as plt #used for plotting\n",
    "import sklearn #machine learning library\n",
    "from sklearn.model_selection import train_test_split #creation of train.test sets\n",
    "\n",
    "#loading and splitting the data into train/test sets\n",
    "data = pd.read_csv('data/affairs_dataset/fair.csv', sep=',')\n",
    "y = (data.affairs > 0).astype(int)\n",
    "X = data.drop('affairs', axis=1)\n",
    "\n",
    "#split the data into train and test sets, with a 70-30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code starts here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73036649214659688"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedAffair = lr.predict(X_test)\n",
    "comparison = np.logical_xor(y_test, predictedAffair)\n",
    "(y_test.shape[0] - np.sum(comparison))/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73036649214659688"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictedAffair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedAffair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean())/ X_train.std()\n",
    "X_test = (X_test - X_test.mean())/ X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73141361256544501"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedAffair = lr.predict(X_test)\n",
    "probs = lr.predict_proba(X_test)\n",
    "comparison = np.logical_xor(y_test, predictedAffair)\n",
    "(y_test.shape[0] - np.sum(comparison))/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73141361256544501"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31780104712041884"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.731413612565\n",
      "AUC: %f 0.745079470642\n",
      "Classification confusion matrix:\n",
      "[[1174  129]\n",
      " [ 384  223]]\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.90      0.82      1303\n",
      "          1       0.63      0.37      0.47       607\n",
      "\n",
      "avg / total       0.72      0.73      0.71      1910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate evaluation metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy: %f\", metrics.accuracy_score(y_test, predictedAffair))\n",
    "print(\"AUC: %f\", metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "print(\"Classification confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, predictedAffair))\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, predictedAffair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72916667  0.72395833  0.70833333  0.7486911   0.70680628  0.7382199\n",
      "  0.7486911   0.70526316  0.68947368  0.74736842]\n",
      "0.724597197345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), X_test, y_test, scoring='accuracy', cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedAffair\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
