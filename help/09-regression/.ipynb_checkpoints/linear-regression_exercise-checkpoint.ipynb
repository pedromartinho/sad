{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression exercise\n",
    "In this exercise we will be working with the [Boston housing dataset](http://facweb.cs.depaul.edu/mobasher/classes/CSC478/Data/housing-dscr.txt), which gives information on housing prices for the suburbs of Boston. See the link for a description of the available parameters.\n",
    "\n",
    "Below we do the first step for you, load the dataset and establish a training and test sets. You will need to implement the following:\n",
    "\n",
    "1) Train a linear regression model for the training data. You can either use the python code or the sklearn implementation.\n",
    "\n",
    "2) Test that the regression model works by computing the regression error on the test set\n",
    "\n",
    "3) (Optional) As the number of records in this dataset is not very extensive, it might be a good idea to use a cross-validation/jackknifing method instead of defining a fixed train/test set. You can give it a try with the function sklearn.cross_validation\n",
    "\n",
    "Consider doing some plotting and printing out of the data along the way to get a feeling of what you are looking at in here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd #used for reading/writing data \n",
    "import numpy as np #numeric library library\n",
    "from matplotlib import pyplot as plt #used for plotting\n",
    "import sklearn #machine learning library\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data into a pandas dataFrame to be similar from our example\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target)\n",
    "\n",
    "#split the data into train and test sets, with a 70-30 split\n",
    "from sklearn.model_selection import train_test_split #creation of train.test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
